---
editor_options:
  chunk_output_type: console
---

# Temporal sampling

In this script, we examine temporal differences in the reporting of observations for the states of Tamil Nadu and Kerala. 


The analyses we carry out include: a) reporting of checklists for every 5-year interval
b) are there significant differences between pre2000 and other time periods

## Prepare libraries
```{r setup_sup_02}
# load libraries
library(data.table)
library(readxl)
library(magrittr)
library(stringr)
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(ggthemes)
library(scico)
library(extrafont)
library(sf)
library(rnaturalearth)
library(auk)

# round any function
round_25 <- function(x, accuracy = 25000) {
  round(x / accuracy) * accuracy
}

# set file paths for auk functions
# To use these two datasets, please download the latest versions from https://ebird.org/data/download and set the file path accordingly. Since these two datasets are extremely large, we have not uploaded the same to GitHub.
# In this study, the version of data loaded corresponds to July 2022.

f_in_ebd <- file.path("data/ebd_IN_relJul-2022.txt")
f_in_sampling <- file.path("data/ebd_sampling_relJul-2022.txt")
```

## Filter data using auk package

Here, we set broad spatial filters to subset all complete checklsits for the states of Kerala and Tamil Nadu for the above list of species.
```{r prep_ebd_filters}
# run filters using auk packages
ebd_filters <- auk_ebd(f_in_ebd, f_in_sampling) %>%
  auk_country(country = "IN") %>%
  auk_state(c("IN-KL", "IN-TN")) %>%
  auk_complete()

# check filters
ebd_filters
```

Below code need not be run if it has been filtered once already and the above path leads to the right dataset. NB: This is a computation heavy process, run with caution.

```{r output_loc}
# specify output location and perform filter
f_out_ebd <- "data/01_ebird-filtered-KL-TN.txt"
f_out_sampling <- "data/01_ebird-filtered-sampling-KL-TN.txt"
```

```{r filter_data}
ebd_filtered <- auk_filter(ebd_filters,
  file = f_out_ebd,
  file_sampling = f_out_sampling, overwrite = TRUE
)
```

## Process filtered data

The data has been filtered above using the auk functions. We will now work with the filtered checklist observations.  

```{r read_data}
# read in the data
# note: running this takes a very long time and I would suggest saving an .RData file after applying the basic filters
ebd <- read_ebd(f_out_ebd)
gc()

# Convert all presences marked 'X' as '1'
ebd <- ebd %>%
  mutate(observation_count = ifelse(observation_count == "X",
    "1", observation_count))

# Convert observation count to numeric
ebd$observation_count <- as.numeric(ebd$observation_count)

# choose columns of interest
columnsOfInterest <- c(
  "checklist_id", "scientific_name", "common_name",
  "observation_count", "locality", "locality_id",
  "locality_type", "latitude", "longitude",
  "observation_date", "time_observations_started",
  "observer_id", "sampling_event_identifier",
  "protocol_type", "duration_minutes",
  "effort_distance_km", "effort_area_ha",
  "number_observers", "species_observed","state",
  "reviewed"
)
ebd <- ebd %>%
  select(matches(columnsOfInterest))
```

## Include only species with scientific names
```{r}
# remove species that are poorly reported (only filter being applied at this stage)
# for example, accounts such as 'Turdidae sp.', are removed and only the latest
# list of scientific names are taken into consideration

trait_dat <- read.csv("data/2022-SoIB-habitat-data.csv")
speciesOfInterest <- data.frame(trait_dat$eBird.Scientific.Name.2021)
names(speciesOfInterest) <- "scientific_name"

# filter for species list above
ebd <- ebd[ebd$scientific_name %in% speciesOfInterest$scientific_name, ]
```

## Subset data by time period

We will divide data into five-year intervals: 2000-2005, 2006-2010, 2011-2015, 2016-2020 and all data before 2000 as a single category. 

```{r}
# separate observation_date as year, month, day
ebd <- ebd %>%
  separate(observation_date, c("year","month","day"))

# subset data by time period
ebd <- ebd %>%
  mutate(timePeriod = case_when(
    year >= 2000 & year < 2005 ~ "2000-2005",
    year >= 2005 & year < 2010 ~ "2005-2010",
    year >= 2010 & year < 2015 ~ "2010-2015",
    year >= 2015 & year < 2020 ~ "2015-2020",
    year >= 2020 ~ "post2020",
    year < 2000 ~ "pre2000"
  ))
```

## Subset data spatially 
```{r}
# read in shapefile of the study area to subset by bounding box

# first, we load the India states boundary from GADM
india_states <- st_read("data/spatial/shapefiles/IND_adm1.shp")

# load tamil nadu and kerala separately
tamil_nadu <- india_states[india_states$NAME_1=="Tamil Nadu",]
box_tn <- st_bbox(tamil_nadu)

kerala <- india_states[india_states$NAME_1=="Kerala",]
box_ker <- st_bbox(kerala)  



# get data spatial coordinates
dataLocs <- data %>%
  map(function(x) {
    select(x, longitude, latitude) %>%
      filter(between(longitude, box["xmin"], box["xmax"]) &
        between(latitude, box["ymin"], box["ymax"]))
  }) %>%
  bind_rows() %>%
  distinct() %>%
  st_as_sf(coords = c("longitude", "latitude")) %>%
  st_set_crs(4326) %>%
  st_intersection(hills)


tn_coords <- setDF(tn_locs) %>%
  st_as_sf(coords = c("longitude", "latitude")) %>%
  `st_crs<-`(4326) %>%
  bind_cols(as.data.table(st_coordinates(.))) %>%
  st_transform(32643) %>%
  mutate(id = 1:nrow(.))








# tamil nadu
tn_ebd <- ebd %>%
  filter(between(longitude, box_tn["xmin"], box_tn["xmax"]) &
  between(latitude, box_tn["ymin"], box_tn["ymax"]))

# tamil nadu
ker_ebd <- ebd %>%
  filter(between(longitude, box_ker["xmin"], box_ker["xmax"]) &
  between(latitude, box_ker["ymin"], box_ker["ymax"]))
```

