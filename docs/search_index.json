[["index.html", "Source code and supplementary material for independent validation of State of India’s birds Section 1 Introduction 1.1 Data processing", " Source code and supplementary material for independent validation of State of India’s birds Vijay Ramesh 2022-11-16 Section 1 Introduction This is the readable version containing analysis that examines eBird data (specifics of the analysis will be updated). Methods and format are derived from https://cornelllabofornithology.github.io/ebird-best-practices/. 1.1 Data processing The data processing for this project is described in the following sections. Navigate through them using the links in the sidebar. "],["visualization-of-all-observations-over-time.html", "Section 2 Visualization of all observations over time 2.1 Prepare libraries 2.2 Subset observations by geographical confines of the study area 2.3 Data cleaning prior to visualization 2.4 Load spatial grids for checklist locations 2.5 Get proportional observation counts across every 25 km x 25 km grid 2.6 Add the list of species 2.7 Checklist distribution 2.8 Figure: Checklist distribution 2.9 Figure: Proportion of checklists reporting species in each grid cell 2.10 save .RData for future scripts", " Section 2 Visualization of all observations over time In this script, we will visualize the overall number of checklists across the Indian subcontinent and repeat the same analysis at the species level. At this stage, no specific filters are applied and we report all analysis for every 25 x 25 km grid size (finer scales/sizes will be used for comparison at a later stage). 2.1 Prepare libraries # load libraries library(data.table) library(readxl) library(magrittr) library(stringr) library(dplyr) library(tidyr) library(readr) library(ggplot2) library(ggthemes) library(scico) library(extrafont) library(sf) library(rnaturalearth) # round any function round_25 &lt;- function(x, accuracy = 25000) { round(x / accuracy) * accuracy } # set file paths for auk functions # To use these two datasets, please download the latest versions from https://ebird.org/data/download and set the file path accordingly. Since these two datasets are extremely large, we have not uploaded the same to GitHub. # In this study, the version of data loaded corresponds to July 2022. f_in_ebd &lt;- file.path(&quot;data/ebd_IN_relJul-2022.txt&quot;) f_in_sampling &lt;- file.path(&quot;data/ebd_sampling_relJul-2022.txt&quot;) 2.2 Subset observations by geographical confines of the study area In this case, the geographical confines correspond to the political boundary of India. # first, we load the India states boundary from GADM india_states &lt;- st_read(&quot;data/spatial/shapefiles/india_states_boundary.shp&quot;) box_in &lt;- st_bbox(india_states) # read in ebd data and subset by state for our analysis # To access the latest dataset, please visit: https://ebird.org/data/download and set the file path accordingly. ebd &lt;- fread(&quot;data/ebd_IN_relJul-2022.txt&quot;) # subsettting by lat-long ebd_in &lt;- ebd[between(LONGITUDE, box_in[&quot;xmin&quot;], box_in[&quot;xmax&quot;]) &amp; between(LATITUDE, box_in[&quot;ymin&quot;], box_in[&quot;ymax&quot;]), ] # resulted in removal of 21 observations in total # make new column names newNames &lt;- str_replace_all(colnames(ebd_in), &quot; &quot;, &quot;_&quot;) %&gt;% str_to_lower() setnames(ebd_in, newNames) # keep useful columns columnsOfInterest &lt;- c( &quot;common_name&quot;, &quot;scientific_name&quot;, &quot;observation_count&quot;, &quot;locality&quot;, &quot;state&quot;,&quot;state_code&quot;,&quot;locality_id&quot;, &quot;locality_type&quot;, &quot;latitude&quot;, &quot;longitude&quot;, &quot;observation_date&quot;, &quot;time_observations_started&quot;, &quot;protocol_type&quot;,&quot;duration_minutes&quot;,&quot;effort_distance_km&quot;, &quot;number_observers&quot;, &quot;group_identifier&quot;, &quot;reviewed&quot;, &quot;sampling_event_identifier&quot; ) ebd_in &lt;- ebd_in[, ..columnsOfInterest] # remove the large ebd file if it&#39;s not required rm(ebd) gc() # run this function to clear up some memory space 2.3 Data cleaning prior to visualization # Convert all presences marked &#39;X&#39; as &#39;1&#39; ebd_in &lt;- ebd_in %&gt;% mutate(observation_count = ifelse(observation_count == &quot;X&quot;, &quot;1&quot;, observation_count )) # Convert observation count to numeric ebd_in$observation_count &lt;- as.numeric(ebd_in$observation_count) 2.4 Load spatial grids for checklist locations Add a spatial filter. # strict spatial filter and assign grid locs &lt;- ebd_in[, .(longitude, latitude)] # transform to UTM coords &lt;- setDF(locs) %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% bind_cols(as.data.table(st_coordinates(.))) %&gt;% st_transform(&quot;+proj=laea +lon_0=80.859375 +lat_0=20.6486698 +datum=WGS84 +units=m +no_defs&quot;) %&gt;% mutate(id = 1:nrow(.)) # make some empty space gc() # convert to UTM for filter india_states &lt;- st_transform(india_states, &quot;+proj=laea +lon_0=80.859375 +lat_0=20.6486698 +datum=WGS84 +units=m +no_defs&quot;) coords &lt;- coords %&gt;% filter(id %in% unlist(st_contains(india_states, coords))) %&gt;% rename(longitude = X, latitude = Y) %&gt;% bind_cols(as.data.table(st_coordinates(.))) %&gt;% st_drop_geometry() %&gt;% as.data.table() # remove unneeded objects rm(locs) gc() coords &lt;- coords[, .N, by = .(longitude, latitude, X, Y)] ebd_in &lt;- merge(ebd_in, coords, all = FALSE, by = c(&quot;longitude&quot;, &quot;latitude&quot;)) ebd_in &lt;- ebd_in[(longitude %in% coords$longitude) &amp; (latitude %in% coords$latitude), ] 2.5 Get proportional observation counts across every 25 km x 25 km grid Analysis of proportional counts estimated at 25km ## Analysis of proportional counts at 25 km for each state # round to 25km cell in UTM coords ebd_in[, `:=`(X = round_25(X), Y = round_25(Y))] # separate observation_date as year, month, day # please note: the below operation takes awhile to run ebd_in &lt;- ebd_in %&gt;% separate(observation_date, c(&quot;year&quot;,&quot;month&quot;,&quot;day&quot;)) gc() # count checklists in cell ebd_summary &lt;- ebd_in[, nchk := length(unique(sampling_event_identifier)), by = .(X, Y)] # count checklists reporting each species in cell and get proportion ebd_summary &lt;- ebd_summary[, .(nrep = length(unique( sampling_event_identifier ))), by = .(X, Y, nchk, scientific_name) ] ebd_summary[, p_rep := nrep / nchk] # complete the dataframe for no reports # keep no reports as NA --- allows filtering based on proportion reporting ebd_summary &lt;- setDF(ebd_summary) %&gt;% complete( nesting(X, Y), scientific_name # , # fill = list(p_rep = 0) ) %&gt;% filter(!is.na(p_rep)) 2.6 Add the list of species In this script, no species is being excluded and we are visualizing data for all 1352 species across the Indian subcontinent. # remove species that are poorly reported (only filter being applied at this stage) # for example, accounts such as &#39;Turdidae sp.&#39;, are removed and only the latest # list of scientific names are taken into consideration species_list &lt;- read.csv(&quot;data/2022-SoIB-species-list.csv&quot;) speciesOfInterest &lt;- data.frame(species_list$Scientific.Name) names(speciesOfInterest) &lt;- &quot;scientific_name&quot; # filter for species list above ebd_summary &lt;- ebd_summary[ebd_summary$scientific_name %in% speciesOfInterest$scientific_name, ] 2.7 Checklist distribution # total number of checklists across unique grids tot_n_chklist &lt;- ebd_summary %&gt;% distinct(X, Y, nchk) # Across India, species have been reported from a total of 4803 unique 25 x 25 km grids # species-specific number of grids spp_grids &lt;- ebd_summary %&gt;% group_by(scientific_name) %&gt;% distinct(X, Y) %&gt;% count(scientific_name, name = &quot;n_grids&quot; ) # Write the above result # total of 1316 species write.csv(spp_grids, &quot;results/01_ngrids-per-spp.csv&quot;, row.names=F) # left-join the datasets # ebd_summary &lt;- left_join(ebd_summary, spp_grids, by = &quot;scientific_name&quot;) 2.8 Figure: Checklist distribution # add land land &lt;- ne_countries( scale = 50, type = &quot;countries&quot;, continent = &quot;asia&quot;, country = &quot;india&quot;, returnclass = c(&quot;sf&quot;) ) # crop land land &lt;- st_transform(land, &quot;+proj=laea +lon_0=80.859375 +lat_0=20.6486698 +datum=WGS84 +units=m +no_defs&quot;) Number of checklists over time 2.9 Figure: Proportion of checklists reporting species in each grid cell Note: Here we visualize the proportion of checklists that report a particular species for every 25 x 25 km cell (no specific filter is being applied). 2.10 save .RData for future scripts save.image(file = &quot;data/01_ebd-India.RData&quot;) "],["temporal-visualization-of-all-observations.html", "Section 3 Temporal visualization of all observations 3.1 Load .Rdata from a previous script 3.2 Subset data by time period 3.3 Checklist distribution over time 3.4 Figure: Checklist distribution by time period 3.5 Testing for differences in number of checklists by time period 3.6 Figure: violinplot of number of checklists by time period 3.7 Figure: Proportion of checklists reporting species in each grid cell by time period", " Section 3 Temporal visualization of all observations In this script, we will visualize all checklist observations temporally to assess if there are biases in reporting over time. For example, are more observations being reported in a particular 5-year interval/time-period when compared to another time period. We also aim to assess if there are significant differences in the number of observations across time periods. ## Prepare libraries # load libraries library(data.table) library(readxl) library(magrittr) library(stringr) library(dplyr) library(tidyr) library(readr) library(ggplot2) library(ggthemes) library(scico) library(extrafont) library(sf) library(rnaturalearth) library(lme4) library(multcomp) library(sjPlot) library(ggstatsplot) library(paletteer) 3.1 Load .Rdata from a previous script load(&quot;data/01_ebd-India.RData&quot;) 3.2 Subset data by time period We will divide data into time-periods/intervals that are currently being used by the State of India’s birds. # subset data by time period ebd_in &lt;- ebd_in %&gt;% mutate(timePeriod = case_when( year &lt;= 1999 ~ &quot;pre2000&quot;, year &gt; 1999 &amp; year &lt;= 2006 ~ &quot;2000-2006&quot;, year &gt; 2006 &amp; year &lt;= 2010 ~ &quot;2007-2010&quot;, year &gt; 2010 &amp; year &lt;= 2012 ~ &quot;2011-2012&quot;, year == 2013 ~ &quot;2013&quot;, year == 2014 ~ &quot;2014&quot;, year == 2015 ~ &quot;2015&quot;, year == 2016 ~ &quot;2016&quot;, year == 2017 ~ &quot;2017&quot;, year == 2018 ~ &quot;2018&quot;, year == 2019 ~ &quot;2019&quot;, year == 2020 ~ &quot;2020&quot;, year == 2021 ~ &quot;2021&quot;, year == 2022 ~ &quot;2022&quot; )) ## count checklists in cell ebd_summary &lt;- ebd_in[, nchk := length(unique(sampling_event_identifier)), by = .(X, Y, timePeriod)] # count checklists reporting each species in cell and get proportion ebd_summary &lt;- ebd_summary[, .(nrep = length(unique( sampling_event_identifier ))), by = .(X, Y, nchk, scientific_name, timePeriod) ] ebd_summary[, p_rep := nrep / nchk] # complete the dataframe for no reports # keep no reports as NA --- allows filtering based on proportion reporting ebd_summary &lt;- setDF(ebd_summary) %&gt;% complete( nesting(X, Y), scientific_name, timePeriod # , # fill = list(p_rep = 0) ) %&gt;% filter(!is.na(p_rep)) # filter for species list above ebd_summary &lt;- ebd_summary[ebd_summary$scientific_name %in% speciesOfInterest$scientific_name, ] 3.3 Checklist distribution over time # total number of checklists across unique grids tot_n_chklist &lt;- ebd_summary %&gt;% distinct(X, Y, nchk, timePeriod) # species-specific number of grids by time Period spp_grids &lt;- ebd_summary %&gt;% group_by(scientific_name, timePeriod) %&gt;% distinct(X, Y) %&gt;% count(scientific_name, name = &quot;n_grids&quot; ) # Write the above two results # total of 1316 species write.csv(spp_grids, &quot;results/02_ngrids-per-spp-by-timePeriod.csv&quot;, row.names=F) 3.4 Figure: Checklist distribution by time period # reordering factors for plotting tot_n_chklist$timePeriod &lt;- factor(tot_n_chklist$timePeriod, levels = c(&quot;pre2000&quot;, &quot;2000-2006&quot;, &quot;2007-2010&quot;,&quot;2011-2012&quot;,&quot;2013&quot;,&quot;2014&quot;,&quot;2015&quot;, &quot;2016&quot;,&quot;2017&quot;,&quot;2018&quot;,&quot;2019&quot;,&quot;2020&quot;,&quot;2021&quot;,&quot;2022&quot;)) # get a plot of number of checklists across grids for each timePeriod plotNchk &lt;- ggplot() + geom_sf(data = land, fill = &quot;grey90&quot;, col = NA) + geom_tile( data = tot_n_chklist, aes(X, Y, fill = nchk), lwd = 0.5, col = &quot;grey90&quot; ) + geom_sf(data = india_states, fill = NA, col = &quot;black&quot;, lwd = 0.3) + scale_fill_scico( palette = &quot;lajolla&quot;, direction = 1, trans = &quot;log10&quot;, limits = c(1, 50000), breaks = 10^c(1:5) ) + facet_wrap(~timePeriod) + coord_sf(xlim = bbox[c(&quot;xmin&quot;, &quot;xmax&quot;)], ylim = bbox[c(&quot;ymin&quot;, &quot;ymax&quot;)]) + theme_few() + theme( legend.position = &quot;right&quot;, axis.title = element_blank(), axis.text.y = element_text(angle = 90), panel.background = element_rect(fill = &quot;lightblue&quot;) ) + labs(fill = &quot;number\\nof\\nchecklists&quot;) # export data ggsave(plotNchk, filename = &quot;figs/fig_number_checklists_25km_by_timePeriod.png&quot;, height = 15, width = 15, device = png(), dpi = 300 ) dev.off() Number of checklists by time period 3.5 Testing for differences in number of checklists by time period # Test if there are significant differences in the number of checklists by time period # add a grid code (to be used in a random effects model) tot_n_chklist &lt;- tot_n_chklist %&gt;% group_by(X,Y) %&gt;% mutate(gridCode = cur_group_id()) %&gt;% ungroup() # Note: this takes a long-time to run glmm_nChk_time &lt;- glmer(nchk ~ timePeriod + (1|gridCode), data = tot_n_chklist, family = poisson(link=&quot;log&quot;)) tukey_nChk_time &lt;- summary(glht(glmm_nChk_time, linfct=mcp(timePeriod =&quot;Tukey&quot;))) cld(tukey_nChk_time) # differences between time periods as revealed through glht # pre2000 2000-2006 2007-2010 2011-2012 2013 2014 2015 # 2016 # &quot;a&quot; &quot;b&quot; &quot;d&quot; &quot;c&quot; &quot;b&quot; &quot;e&quot; &quot;f&quot; # &quot;g&quot; # 2017 2018 2019 2020 2021 2022 # &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;l&quot; &quot;m&quot; &quot;k&quot; # note that the random effects plot suggests differences attributed to grid code/the 25 x 25 km cell and there are significant differences as some grids are sampled much more than others. 3.6 Figure: violinplot of number of checklists by time period # create log values of nChk tot_n_chklist$logNchk &lt;- log(tot_n_chklist$nchk) fig_nchk_time &lt;- ggbetweenstats( data = tot_n_chklist, x = timePeriod, y = logNchk, type = &quot;robust&quot;, ## type of statistics xlab = &quot;Time Period&quot;, ylab = &quot;log Number of checklists&quot;, title = &quot;Distribution of checklists by time period across 25 x 25 km grid cells&quot;, plot.type = &quot;boxviolin&quot;, pairwise.comparisons = F)+ ## Note: this is done to avoid plot cluttering scale_color_manual(values = c(&quot;#9EB0FFFF&quot;, &quot;#6FA9E8FF&quot;,&quot;#4294C2FF&quot;, &quot;#2C7192FF&quot;,&quot;#1D4D63FF&quot;,&quot;#122C39FF&quot;,&quot;#101317FF&quot;,&quot;#230B02FF&quot;,&quot;#3B1000FF&quot;, &quot;#5C1D08FF&quot;,&quot;#863B26FF&quot;,&quot;#AD5F50FF&quot;,&quot;#D5857DFF&quot;,&quot;#FFACACFF&quot;)) + theme(plot.title = element_text(family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot;), axis.title = element_text(family = &quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot;), axis.text = element_text(family=&quot;Century Gothic&quot;,size = 14), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;, color=&quot;#1b2838&quot; )) ggsave(fig_nchk_time, filename = &quot;figs/fig_logChecklists_timePeriod.png&quot;, width = 15, height = 10, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() ## Note: there are atleast 77 different pairwise comparisons where there is a significant difference in the log Number of checklists across the time periods compared (using a Yuen&#39;s trimmed means test) ## Please view the statistics below for more details stats_timePeriod_logNChk &lt;- pairwise_comparisons(tot_n_chklist, timePeriod, logNchk, type = &quot;robust&quot;) %&gt;% filter(p.value &lt;= 0.05) %&gt;% data.frame() write.csv(stats_timePeriod_logNChk[,-10], &quot;results/02_pairwiseComparisons_timePeriod_logNchk.csv&quot;, row.names = F) Distribution of the log number of checklists across every 25 x 25 km grid cells by time period. Here, n refers to the number of unique grid cells for which data exists/was reported for each time period. Please refer to the .csv outlining the results of the pairwise comparisons tests (Yuen’s trimmed means test) 3.7 Figure: Proportion of checklists reporting species in each grid cell by time period Note: Here we visualize the proportion of checklists that report a particular species for every 25 x 25 km cell (no specific filter is being applied) for each time period # reordering factors for plotting ebd_summary$timePeriod &lt;- factor(ebd_summary$timePeriod, levels = c(&quot;pre2000&quot;, &quot;2000-2006&quot;, &quot;2007-2010&quot;,&quot;2011-2012&quot;,&quot;2013&quot;,&quot;2014&quot;,&quot;2015&quot;, &quot;2016&quot;,&quot;2017&quot;,&quot;2018&quot;,&quot;2019&quot;,&quot;2020&quot;,&quot;2021&quot;,&quot;2022&quot;)) # run the loop to create a list of plots # Note: this step takes a long time to run (plots created for &gt;1000 spp) for(i in 1:length(unique(ebd_summary$scientific_name))) { a &lt;- unique(ebd_summary$scientific_name)[i] data &lt;- ebd_summary[ebd_summary$scientific_name==a,] g1 &lt;- ggplot() + geom_sf(data = land, fill = &quot;grey90&quot;, col = NA) + geom_tile( data = data, aes(X, Y, fill = p_rep), lwd = 0.5, col = &quot;grey90&quot; ) + geom_sf(data = india_states, fill = NA, col = &quot;black&quot;, lwd = 0.3) + scale_fill_scico(palette = &quot;lajolla&quot;, direction = 1, label = scales::percent) + facet_wrap(~timePeriod) + coord_sf(xlim = bbox[c(&quot;xmin&quot;, &quot;xmax&quot;)], ylim = bbox[c(&quot;ymin&quot;, &quot;ymax&quot;)]) + labs(title = a)+ ggthemes::theme_few( base_family = &quot;Century Gothic&quot;, base_size = 25 ) + theme(plot.title = element_text(family = &quot;Century Gothic&quot;, size = 22, face = &quot;bold&quot;), legend.position = &quot;right&quot;, strip.text = element_text(face = &quot;italic&quot;), legend.title = element_text(family=&quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot;), legend.key.size = unit(1,&quot;cm&quot;), legend.text = element_text(family=&quot;Century Gothic&quot;,size = 16), axis.title = element_blank(), axis.text.y = element_text(angle = 90), panel.background = element_rect(fill = &quot;lightblue&quot;) ) + labs(fill = &quot;prop.\\nreporting\\nchecklists&quot;) ggsave(filename=&quot;&quot;,width=20, height=22, units=&quot;in&quot;, dpi = 300, plot=g1, device=&quot;png&quot;, path = paste(&quot;figs/figs_speciesProportions_by_timePeriod/&quot;, paste(a, &quot;.png&quot;, sep=&quot;&quot;), sep=&quot;&quot;)) } dev.off() "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
