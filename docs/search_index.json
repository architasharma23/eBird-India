[["index.html", "Source code and supplementary material for independent validation of State of India’s birds Section 1 Introduction 1.1 Data processing", " Source code and supplementary material for independent validation of State of India’s birds Vijay Ramesh 2022-09-30 Section 1 Introduction This is the readable version containing analysis that examines eBird data (specifics of the analysis will be updated). Methods and format are derived from https://cornelllabofornithology.github.io/ebird-best-practices/. 1.1 Data processing The data processing for this project is described in the following sections. Navigate through them using the links in the sidebar. "],["spatial-sampling.html", "Section 2 Spatial sampling 2.1 Prepare libraries 2.2 Subset observations by geographical confines of the study area 2.3 Data cleaning prior to visualization 2.4 Load spatial grids for checklist locations 2.5 Get proportional observation counts across every 25 km x 25 km grid 2.6 Checklist distribution 2.7 Figure: Checklist distribution 2.8 What species are reported sufficiently in checklists? 2.9 Figure: Proportion of checklists reporting species in each grid cell 2.10 write the species lists to file", " Section 2 Spatial sampling In this script, we will examine data across multiple states with a focus on Kerala and Tamil Nadu separately. Since the Kerala Bird Atlas has been released, we suspect that the data is more structured when compared to the state of Tamil Nadu. we do not make an attempt to compare temporal sampling across scales in this script. For the state of Tamil Nadu and Kerala, we examine the proportion of checklists reported at 25 x 25 km grid level. 2.1 Prepare libraries # load libraries library(data.table) library(readxl) library(magrittr) library(stringr) library(dplyr) library(tidyr) library(readr) library(ggplot2) library(ggthemes) library(scico) library(extrafont) library(sf) library(rnaturalearth) # round any function round_25 &lt;- function(x, accuracy = 25000) { round(x / accuracy) * accuracy } round_10 &lt;- function(x, accuracy = 10000) { round(x / accuracy) * accuracy } round_5 &lt;- function(x, accuracy = 5000) { round(x / accuracy) * accuracy } # set file paths for auk functions # To use these two datasets, please download the latest versions from https://ebird.org/data/download and set the file path accordingly. Since these two datasets are extremely large, we have not uploaded the same to GitHub. # In this study, the version of data loaded corresponds to July 2022. f_in_ebd &lt;- file.path(&quot;data/ebd_IN_relJul-2022.txt&quot;) f_in_sampling &lt;- file.path(&quot;data/ebd_sampling_relJul-2022.txt&quot;) 2.2 Subset observations by geographical confines of the study area In this case, the geographical confines correspond to the states of Tamil Nadu and Kerala. # read in shapefile of the study area to subset by bounding box # first, we load the India states boundary from GADM india_states &lt;- st_read(&quot;data/spatial/shapefiles/IND_adm1.shp&quot;) # load tamil nadu and kerala separately tamil_nadu &lt;- india_states[india_states$NAME_1==&quot;Tamil Nadu&quot;,] box_tn &lt;- st_bbox(tamil_nadu) kerala &lt;- india_states[india_states$NAME_1==&quot;Kerala&quot;,] box_ker &lt;- st_bbox(kerala) # read in ebd data and subset by state for our analysis # To access the latest dataset, please visit: https://ebird.org/data/download and set the file path accordingly. ebd &lt;- fread(&quot;data/ebd_IN_relJul-2022.txt&quot;) # tamil nadu tn_ebd &lt;- ebd[between(LONGITUDE, box_tn[&quot;xmin&quot;], box_tn[&quot;xmax&quot;]) &amp; between(LATITUDE, box_tn[&quot;ymin&quot;], box_tn[&quot;ymax&quot;]), ] # make new column names newNames &lt;- str_replace_all(colnames(tn_ebd), &quot; &quot;, &quot;_&quot;) %&gt;% str_to_lower() setnames(tn_ebd, newNames) # keep useful columns columnsOfInterest &lt;- c( &quot;common_name&quot;, &quot;scientific_name&quot;, &quot;observation_count&quot;, &quot;locality&quot;, &quot;locality_id&quot;, &quot;locality_type&quot;, &quot;latitude&quot;, &quot;longitude&quot;, &quot;observation_date&quot;, &quot;sampling_event_identifier&quot; ) tn_ebd &lt;- tn_ebd[, ..columnsOfInterest] # kerala ker_ebd &lt;- ebd[between(LONGITUDE, box_ker[&quot;xmin&quot;], box_ker[&quot;xmax&quot;]) &amp; between(LATITUDE, box_ker[&quot;ymin&quot;], box_ker[&quot;ymax&quot;]), ] # make new column names newNames &lt;- str_replace_all(colnames(ker_ebd), &quot; &quot;, &quot;_&quot;) %&gt;% str_to_lower() setnames(ker_ebd, newNames) # keep useful columns columnsOfInterest &lt;- c( &quot;common_name&quot;, &quot;scientific_name&quot;, &quot;observation_count&quot;, &quot;locality&quot;, &quot;locality_id&quot;, &quot;locality_type&quot;, &quot;latitude&quot;, &quot;longitude&quot;, &quot;observation_date&quot;, &quot;sampling_event_identifier&quot; ) ker_ebd &lt;- ker_ebd[, ..columnsOfInterest] # remove the large ebd file if it&#39;s not required rm(ebd) gc() # run this function to clear up some memory space 2.3 Data cleaning prior to visualization # Convert all presences marked &#39;X&#39; as &#39;1&#39; tn_ebd &lt;- tn_ebd %&gt;% mutate(observation_count = ifelse(observation_count == &quot;X&quot;, &quot;1&quot;, observation_count )) ker_ebd &lt;- ker_ebd %&gt;% mutate(observation_count = ifelse(observation_count == &quot;X&quot;, &quot;1&quot;, observation_count )) # Convert observation count to numeric tn_ebd$observation_count &lt;- as.numeric(tn_ebd$observation_count) ker_ebd$observation_count &lt;- as.numeric(ker_ebd$observation_count) 2.4 Load spatial grids for checklist locations Add a spatial filter. # strict spatial filter and assign grid tn_locs &lt;- tn_ebd[, .(longitude, latitude)] ker_locs &lt;- ker_ebd[, .(longitude, latitude)] # transform to UTM tn_coords &lt;- setDF(tn_locs) %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% bind_cols(as.data.table(st_coordinates(.))) %&gt;% st_transform(32643) %&gt;% mutate(id = 1:nrow(.)) ker_coords &lt;- setDF(ker_locs) %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% bind_cols(as.data.table(st_coordinates(.))) %&gt;% st_transform(32643) %&gt;% mutate(id = 1:nrow(.)) # convert to UTM for filter tamil_nadu &lt;- st_transform(tamil_nadu, 32643) kerala &lt;- st_transform(kerala, 32643) tn_coords &lt;- tn_coords %&gt;% filter(id %in% unlist(st_contains(tamil_nadu, tn_coords))) %&gt;% rename(longitude = X, latitude = Y) %&gt;% bind_cols(as.data.table(st_coordinates(.))) %&gt;% st_drop_geometry() %&gt;% as.data.table() ker_coords &lt;- ker_coords %&gt;% filter(id %in% unlist(st_contains(kerala, ker_coords))) %&gt;% rename(longitude = X, latitude = Y) %&gt;% bind_cols(as.data.table(st_coordinates(.))) %&gt;% st_drop_geometry() %&gt;% as.data.table() # remove unneeded objects rm(tn_locs, ker_locs) gc() tn_coords &lt;- tn_coords[, .N, by = .(longitude, latitude, X, Y)] ker_coords &lt;- ker_coords[, .N, by = .(longitude, latitude, X, Y)] tn_ebd &lt;- merge(tn_ebd, tn_coords, all = FALSE, by = c(&quot;longitude&quot;, &quot;latitude&quot;)) tn_ebd &lt;- tn_ebd[(longitude %in% tn_coords$longitude) &amp; (latitude %in% tn_coords$latitude), ] ker_ebd &lt;- merge(ker_ebd, ker_coords, all = FALSE, by = c(&quot;longitude&quot;, &quot;latitude&quot;)) ker_ebd &lt;- ker_ebd[(longitude %in% ker_coords$longitude) &amp; (latitude %in% ker_coords$latitude), ] 2.5 Get proportional observation counts across every 25 km x 25 km grid Analysis of proportional counts estimated at 25km ## Analysis of proportional counts at 25 km for each state # round to 25km cell in UTM coords tn_ebd[, `:=`(X = round_25(X), Y = round_25(Y))] ker_ebd[, `:=`(X = round_25(X), Y = round_25(Y))] # count checklists in cell tn_ebd_summary &lt;- tn_ebd[, nchk := length(unique(sampling_event_identifier)), by = .(X, Y)] ker_ebd_summary &lt;- ker_ebd[, nchk := length(unique(sampling_event_identifier)), by = .(X, Y)] # count checklists reporting each species in cell and get proportion tn_ebd_summary &lt;- tn_ebd_summary[, .(nrep = length(unique( sampling_event_identifier ))), by = .(X, Y, nchk, scientific_name) ] tn_ebd_summary[, p_rep := nrep / nchk] ker_ebd_summary &lt;- ker_ebd_summary[, .(nrep = length(unique( sampling_event_identifier ))), by = .(X, Y, nchk, scientific_name) ] ker_ebd_summary[, p_rep := nrep / nchk] # complete the dataframe for no reports # keep no reports as NA --- allows filtering based on proportion reporting tn_ebd_summary &lt;- setDF(tn_ebd_summary) %&gt;% complete( nesting(X, Y), scientific_name # , # fill = list(p_rep = 0) ) %&gt;% filter(!is.na(p_rep)) ker_ebd_summary &lt;- setDF(ker_ebd_summary) %&gt;% complete( nesting(X, Y), scientific_name # , # fill = list(p_rep = 0) ) %&gt;% filter(!is.na(p_rep)) # remove species that are poorly reported (only filter being applied at this stage) # for example, accounts such as &#39;Turdidae sp.&#39;, are removed and only the latest # list of scientific names are taken into consideration trait_dat &lt;- read.csv(&quot;data/2022-SoIB-habitat-data.csv&quot;) speciesOfInterest &lt;- data.frame(trait_dat$eBird.Scientific.Name.2021) names(speciesOfInterest) &lt;- &quot;scientific_name&quot; # filter for species list above (not running this as we are currently not applying filters) tn_ebd_summary &lt;- tn_ebd_summary[tn_ebd_summary$scientific_name %in% speciesOfInterest$scientific_name, ] ker_ebd_summary &lt;- ker_ebd_summary[ker_ebd_summary$scientific_name %in% speciesOfInterest$scientific_name, ] 2.6 Checklist distribution # total number of checklists across unique grids tn_tot_n_chklist &lt;- tn_ebd_summary %&gt;% distinct(X, Y, nchk) ker_tot_n_chklist &lt;- ker_ebd_summary %&gt;% distinct(X, Y, nchk) # Tamil Nadu has a total of 257 unique grids (25 km x 25 km) # Kerala has a total of 96 unique grids (25 km x 25 km) # species-specific number of grids tn_spp_grids &lt;- tn_ebd_summary %&gt;% group_by(scientific_name) %&gt;% distinct(X, Y) %&gt;% count(scientific_name, name = &quot;n_grids&quot; ) ker_spp_grids &lt;- ker_ebd_summary %&gt;% group_by(scientific_name) %&gt;% distinct(X, Y) %&gt;% count(scientific_name, name = &quot;n_grids&quot; ) # Write the above two results write.csv(tn_spp_grids, &quot;results/01_ngrids-per-spp-TamilNadu.csv&quot;, row.names=F) write.csv(ker_spp_grids, &quot;results/01_ngrids-per-spp-Kerala.csv&quot;, row.names=F) # left-join the datasets tn_ebd_summary &lt;- left_join(tn_ebd_summary, tn_spp_grids, by = &quot;scientific_name&quot;) ker_ebd_summary &lt;- left_join(ker_ebd_summary, ker_spp_grids, by = &quot;scientific_name&quot;) 2.7 Figure: Checklist distribution # add land land &lt;- ne_countries( scale = 50, type = &quot;countries&quot;, continent = &quot;asia&quot;, country = &quot;india&quot;, returnclass = c(&quot;sf&quot;) ) # crop land land &lt;- st_transform(land, 32643) Number of checklists over time for the state of Tamil Nadu Number of checklists over time for the state of Kerala 2.8 What species are reported sufficiently in checklists? Here, we estimate the proportion of species that are reported in atleast 50% of checklists across each grid (grid size: 25 km x 25 km) p_cutoff &lt;- 0.05 # Proportion of checklists a species has been reported in tn_grid_proportions &lt;- tn_ebd_summary %&gt;% group_by(scientific_name) %&gt;% tally(p_rep &gt;= p_cutoff) %&gt;% mutate(prop_grids_cut = n / (tn_spp_grids$n_grids)) %&gt;% arrange(desc(prop_grids_cut)) tn_grid_prop_cut &lt;- filter( tn_grid_proportions, prop_grids_cut &gt;= p_cutoff ) ker_grid_proportions &lt;- ker_ebd_summary %&gt;% group_by(scientific_name) %&gt;% tally(p_rep &gt;= p_cutoff) %&gt;% mutate(prop_grids_cut = n / (ker_spp_grids$n_grids)) %&gt;% arrange(desc(prop_grids_cut)) ker_grid_prop_cut &lt;- filter( ker_grid_proportions, prop_grids_cut &gt;= p_cutoff ) # Write the results write.csv(tn_grid_prop_cut, &quot;results/01_prop-grids-per-spp-TamilNadu.csv&quot;, row.names = F) write.csv(ker_grid_prop_cut, &quot;results/01_prop-grids-per-spp-Kerala.csv&quot;, row.names = F) # Identifying the number of species that occur in potentially &lt;5% of all lists tn_total_number_lists &lt;- sum(tn_tot_n_chklist$nchk) ker_total_number_lists &lt;- sum(ker_tot_n_chklist$nchk) tn_spp_sum_chk &lt;- tn_ebd_summary %&gt;% distinct(X, Y, scientific_name, nrep) %&gt;% group_by(scientific_name) %&gt;% mutate(sum_chk = sum(nrep)) %&gt;% distinct(scientific_name, sum_chk) ker_spp_sum_chk &lt;- ker_ebd_summary %&gt;% distinct(X, Y, scientific_name, nrep) %&gt;% group_by(scientific_name) %&gt;% mutate(sum_chk = sum(nrep)) %&gt;% distinct(scientific_name, sum_chk) # 58 species of the list of 527 occur in &gt;5% of all checklists for Tamil Nadu tn_prop_all_lists &lt;- tn_spp_sum_chk %&gt;% mutate(prop_lists = sum_chk / tn_total_number_lists) %&gt;% arrange(desc(prop_lists)) # 66 species of the list of 526 occur in 5% of all checklists for Kerala ker_prop_all_lists &lt;- ker_spp_sum_chk %&gt;% mutate(prop_lists = sum_chk / ker_total_number_lists) %&gt;% arrange(desc(prop_lists)) 2.9 Figure: Proportion of checklists reporting species in each grid cell Note: Here we plot all species that occur in atleast 5% of all checklists across half of the 25 x 25 km cells from where they have been reported 2.10 write the species lists to file # write the list of species that occur in at least 5% of checklists across a minimum of 50% of the grids they have been reported in tn_sp_list &lt;- semi_join(speciesOfInterest, tn_grid_prop_cut, by = &quot;scientific_name&quot;) ker_sp_list &lt;- semi_join(speciesOfInterest, ker_grid_prop_cut, by = &quot;scientific_name&quot;) write.csv(tn_sp_list, &quot;results/01_list-of-species-cutoff50-TamilNadu.csv&quot;, row.names = F) write.csv(ker_sp_list, &quot;results/01_list-of-species-cutoff50-Kerala.csv&quot;, row.names = F) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
